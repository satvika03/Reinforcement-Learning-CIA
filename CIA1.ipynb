{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "y1MiecghuJQQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset dataset.txt contains 10,000 instances corrresponding to distinct site visits by users-events in the language of this part. Each instance comprises 102 space-delimited columns of integers:\n",
        "\n",
        "\n",
        "*   Column 1: The arm played by a\n",
        "uniformly-random policy out of 10 arms (news articles)\n",
        "*   Column 2: The reward received from the arm played|1 if the user clicked 0 otherwise\n",
        "\n",
        "*   Columns 3: The 100-dim flattened context; 10 features per arm (incorporating the content of the article and its match with the visiting user).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ynwSbxQvdXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data and reshape based on provided code snippet\n",
        "data = np.loadtxt(\"/content/dataset.txt\")\n",
        "arms, rewards, contexts = data[:, 0], data[:, 1], data[:, 2:]\n",
        "arms = arms.astype(int)\n",
        "rewards = rewards.astype(float)\n",
        "contexts = contexts.astype(float)\n",
        "n_arms = len(np.unique(arms))  # Number of unique arms\n",
        "n_events = len(contexts)        # Number of events (rounds)\n",
        "n_dims = int(len(contexts[0]) / n_arms)  # Number of features per arm\n",
        "contexts = contexts.reshape(n_events, n_arms, n_dims)"
      ],
      "metadata": {
        "id": "eZiwPZYFuK6r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize UCB parameters\n",
        "counts = np.zeros(n_arms)     # Track number of times each arm is chosen\n",
        "values = np.zeros(n_arms)     # Track cumulative reward for each arm\n",
        "cumulative_reward = 0         # Track total reward for benchmarking"
      ],
      "metadata": {
        "id": "mQDyEbrPuyL4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = 2  # Exploration parameter, typically tuned\n",
        "\n",
        "# Run the UCB algorithm over each event\n",
        "for t in range(n_events):\n",
        "    # Step 1: Compute the UCB score for each arm\n",
        "    ucb_values = np.zeros(n_arms)\n",
        "    for arm in range(n_arms):\n",
        "        if counts[arm] > 0:\n",
        "            # Calculate UCB using current reward estimate and exploration bonus\n",
        "            mean_reward = values[arm] / counts[arm]\n",
        "            bonus = c * np.sqrt(np.log(t + 1) / counts[arm])\n",
        "            ucb_values[arm] = mean_reward + bonus\n",
        "        else:\n",
        "            # Initialize unexplored arms with a high UCB to ensure they get explored\n",
        "            ucb_values[arm] = float('inf')\n",
        "\n",
        "    # Step 2: Select the arm with the highest UCB score\n",
        "    chosen_arm = np.argmax(ucb_values)\n",
        "\n",
        "    # Step 3: Observe reward for the chosen arm\n",
        "    observed_reward = rewards[t] if arms[t] == chosen_arm else 0\n",
        "\n",
        "    # Step 4: Update the chosen arm's count and cumulative reward\n",
        "    counts[chosen_arm] += 1\n",
        "    values[chosen_arm] += observed_reward\n",
        "    cumulative_reward += observed_reward"
      ],
      "metadata": {
        "id": "qYdY-_qhvAkg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output benchmarking metrics\n",
        "print(\"Total cumulative reward:\", cumulative_reward)\n",
        "print(\"Selection count per arm:\", counts)\n",
        "print(\"Average reward per arm:\", values / np.maximum(counts, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0tBA5tpvGOu",
        "outputId": "ba92ac6a-7c8e-4cbc-bf5a-1c82c1ef1128"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total cumulative reward: 90.0\n",
            "Selection count per arm: [ 924. 1167. 1113.  953.  973.  973. 1058.  924.  972.  943.]\n",
            "Average reward per arm: [0.00108225 0.02313625 0.01886792 0.00419727 0.0061665  0.0061665\n",
            " 0.01417769 0.00108225 0.00617284 0.00318134]\n"
          ]
        }
      ]
    }
  ]
}